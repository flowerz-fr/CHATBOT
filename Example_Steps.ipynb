{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'index-orano-investigations' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "from  index_manager import IndexManager\n",
    "index_manager = IndexManager()\n",
    "index_manager.delete_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from storage_manager import AzureBlobStorageManager\n",
    "\n",
    "\n",
    "manager = AzureBlobStorageManager() # Initialize the manager\n",
    "# manager.create_container()  # Create a container\n",
    "# manager.upload_directory()  # Upload a directory\n",
    "manager.download_blobs()    # Download all blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directory_processor import DirectoryProcessor\n",
    "\n",
    "directory_processor = DirectoryProcessor(manager.get_download_folder_path())\n",
    "dataset = directory_processor.process_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_models import AzureOpenAIManager\n",
    "\n",
    "Model = AzureOpenAIManager()\n",
    "embeddings = Model.create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader_manager import DocumentLoaderManager\n",
    "\n",
    "loader_manager = DocumentLoaderManager(data=dataset, page_content_column=\"page_content\")\n",
    "\n",
    "try:\n",
    "    documents = loader_manager.load_documents_from_dataframe()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splitter_manager import DocumentSplitter\n",
    "\n",
    "splitter = DocumentSplitter()\n",
    "\n",
    "try:\n",
    "    # Split the documents\n",
    "    splits = splitter.split_documents(documents)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_store_manager import VectorStoreManager\n",
    "\n",
    "vector_store_manager = VectorStoreManager()\n",
    "vector_test = vector_store_manager.add_documents(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever_manager import ManagerRetrieve\n",
    "\n",
    "retriever_manager = ManagerRetrieve()\n",
    "retriever_manager.create_retriever()\n",
    "retriever_manager.get_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QA_manager import QuestionAnswerManager\n",
    "\n",
    "qa_manager = QuestionAnswerManager()\n",
    "result = qa_manager.ask(\"DDD des PE de boues sur la fosse 217-02 du DEG \")\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answer_manager import ResultProcessor\n",
    "\n",
    "answer_manager = ResultProcessor()\n",
    "answer_manager.create_json_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from storage_manager import AzureBlobStorageManager\n",
    "\n",
    "\n",
    "manager = AzureBlobStorageManager() # Initialize the manager\n",
    "# manager.create_container()  # Create a container\n",
    "# manager.upload_directory()  # Upload a directory\n",
    "manager.download_blobs()    # Download all blobs\n",
    "\n",
    "from directory_processor import DirectoryProcessor\n",
    "\n",
    "directory_processor = DirectoryProcessor(manager.get_download_folder_path())\n",
    "dataset = directory_processor.process_directory()\n",
    "\n",
    "from llm_models import AzureOpenAIManager\n",
    "\n",
    "Model = AzureOpenAIManager()\n",
    "embeddings = Model.create_embeddings()\n",
    "\n",
    "from loader_manager import DocumentLoaderManager\n",
    "\n",
    "loader_manager = DocumentLoaderManager(data=dataset, page_content_column=\"page_content\")\n",
    "\n",
    "try:\n",
    "    documents = loader_manager.load_documents_from_dataframe()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "\\\n",
    "from splitter_manager import DocumentSplitter\n",
    "\n",
    "splitter = DocumentSplitter()\n",
    "\n",
    "try:\n",
    "    # Split the documents\n",
    "    splits = splitter.split_documents(documents)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    \n",
    "from vector_store_manager import VectorStoreManager\n",
    "\n",
    "vector_store_manager = VectorStoreManager()\n",
    "vector_test = vector_store_manager.add_documents(splits)\n",
    "\n",
    "\n",
    "from retriever_manager import ManagerRetrieve\n",
    "\n",
    "retriever_manager = ManagerRetrieve()\n",
    "retriever_manager.create_retriever()\n",
    "retriever_manager.get_retriever()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from prompt_manager import PromptManager\n",
    "from llm_models import AzureOpenAIManager\n",
    "from retriever_manager import ManagerRetrieve\n",
    "from answer_manager import ResultProcessor\n",
    "from storage_manager import AzureBlobStorageManager\n",
    "from directory_processor import DirectoryProcessor\n",
    "from loader_manager import DocumentLoaderManager\n",
    "from splitter_manager import DocumentSplitter\n",
    "from vector_store_manager import VectorStoreManager\n",
    "\n",
    "class QuestionAnswerManager:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the components necessary for the QuestionAnswerManager, including \n",
    "        the language model, retriever, and prompt.\n",
    "        \"\"\"\n",
    "        self.llm = AzureOpenAIManager().create_chat()  # Initialize the Azure OpenAI model\n",
    "        self.retriever = ManagerRetrieve().get_retriever()  # Initialize the retriever\n",
    "        self.prompt = PromptManager().get_prompt()  # Get the system prompt template\n",
    "        \n",
    "        # Combine the LLM and the prompt into a document processing chain\n",
    "        self.question_answer_chain = create_stuff_documents_chain(self.llm, self.prompt)\n",
    "        \n",
    "        # Create the final chain that retrieves documents and answers questions\n",
    "        self.chain = create_retrieval_chain(self.retriever, self.question_answer_chain)\n",
    "    \n",
    "    def ask(self, user_query):\n",
    "        \"\"\"\n",
    "        Process the user query by invoking the retrieval chain, then process the result \n",
    "        to extract relevant information and return a JSON object.\n",
    "        \n",
    "        :param user_query: The query from the user.\n",
    "        :return: A JSON object with the input, answer, and sources.\n",
    "        \"\"\"\n",
    "        # Invoke the chain with the user query\n",
    "        result = self.chain.invoke({\"input\": user_query})\n",
    "        \n",
    "        # Process the result to create a JSON object\n",
    "        result = ResultProcessor().create_json_result(result)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_data():\n",
    "        \"\"\"\n",
    "        A method that handles the preparation of the dataset, including downloading blobs,\n",
    "        processing directories, splitting documents, and storing vectors.\n",
    "        \"\"\"\n",
    "        # Initialize the Azure Blob Storage Manager and download blobs\n",
    "        manager = AzureBlobStorageManager()\n",
    "        manager.download_blobs()  # Download all blobs\n",
    "        \n",
    "        # Process the downloaded directory and extract datasets\n",
    "        directory_processor = DirectoryProcessor(manager.get_download_folder_path())\n",
    "        dataset = directory_processor.process_directory()\n",
    "        \n",
    "        # Create embeddings using the Azure OpenAI model\n",
    "        model = AzureOpenAIManager()\n",
    "        embeddings = model.create_embeddings()\n",
    "        \n",
    "        # Load documents from the processed dataset\n",
    "        loader_manager = DocumentLoaderManager(data=dataset, page_content_column=\"page_content\")\n",
    "        try:\n",
    "            documents = loader_manager.load_documents_from_dataframe()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading documents: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "        # Split the loaded documents into manageable chunks\n",
    "        splitter = DocumentSplitter()\n",
    "        try:\n",
    "            splits = splitter.split_documents(documents)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while splitting documents: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "        # Store the document chunks in a vector store\n",
    "        vector_store_manager = VectorStoreManager()\n",
    "        vector_store_manager.add_documents(splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: downloaded_files\\DEG\\ELH-2018-022986.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2019-014855.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2019-017580.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2019-022027.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2019-027845.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2020-033633.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2020-036076.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2021-001129.pdf\n",
      "File already exists: downloaded_files\\DEG\\ELH-2021-021517.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2019-027755.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2019-029034.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2019-036670.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2019-046650.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2019-065388.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2019-073706.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2020-057124.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2020-061875.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2020-061889.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2020-064506.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2020-065804.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2021-008655.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2021-015259.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2021-028061.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2023-051569.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2023-062147.pdf\n",
      "File already exists: downloaded_files\\HADE\\ELH-2023-069523.pdf\n",
      "File already exists: downloaded_files\\HAO\\ELH-2023-011992.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-011556.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-012662.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-016300.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-017233.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-019259.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-038149.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2019-071998.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-027068.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-027076.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-027077.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-027202.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-050540.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-050540_0.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-051525.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2020-064657.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-000173.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-002107.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-004857.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-005622.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-010901.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-020602.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-030101.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-032169.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-032189.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-034464.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-042695.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-051359.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-067343.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2021-070709.pdf\n",
      "File already exists: downloaded_files\\HAON\\ELH-2022-004213.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-011556.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-012662.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-016300.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-017233.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-019259.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-038149.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2019-071998.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-027068.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-027076.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-027077.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-027202.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-032500.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-050540.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-050540_0.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-051525.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2020-064657.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-000173.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-002107.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-004857.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-005622.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-010901.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-020602.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-030101.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-032169.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-032189.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-034464.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-042695.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-051359.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-067343.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2021-070709.pdf\n",
      "File already exists: downloaded_files\\HAPF\\ELH-2022-004213.pdf\n",
      "File already exists: downloaded_files\\NORD_OUEST\\ELH-2022-063589.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2023-000422.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2023-001532.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2023-005541.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2023-026550.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2023-029462.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2023-049187.pdf\n",
      "File already exists: downloaded_files\\STE2\\ELH-2024-002915.pdf\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AzureBlobStorageManager' object has no attribute 'get_downloaded_files_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare the data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mQuestionAnswerManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the question-answer manager\u001b[39;00m\n\u001b[0;32m      5\u001b[0m qa_manager \u001b[38;5;241m=\u001b[39m QuestionAnswerManager()\n",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m, in \u001b[0;36mQuestionAnswerManager.prepare_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m manager\u001b[38;5;241m.\u001b[39mdownload_blobs()  \u001b[38;5;66;03m# Download all blobs\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Process the downloaded directory and extract datasets\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m directory_processor \u001b[38;5;241m=\u001b[39m DirectoryProcessor(\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_downloaded_files_path\u001b[49m())\n\u001b[0;32m     56\u001b[0m dataset \u001b[38;5;241m=\u001b[39m directory_processor\u001b[38;5;241m.\u001b[39mprocess_directory()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Create embeddings using the Azure OpenAI model\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AzureBlobStorageManager' object has no attribute 'get_downloaded_files_path'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the data\n",
    "QuestionAnswerManager.prepare_data()\n",
    "\n",
    "# Initialize the question-answer manager\n",
    "qa_manager = QuestionAnswerManager()\n",
    "\n",
    "# Ask a question\n",
    "user_question = \"Quel est l'objectif de l'investigation sur l’ensemble porte-lame cellule 904?\"\n",
    "response = qa_manager.ask(user_question)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
